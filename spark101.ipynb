{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4479a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f35665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/05 08:58:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffab873",
   "metadata": {},
   "source": [
    "1) Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "* The name of the column should be language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e2ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame({'language': ['Python', 'Java', 'SQL', 'R', 'Ruby', 'PowerShell', 'PySpark', 'JavaScript', 'C++']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eade4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc086769",
   "metadata": {},
   "source": [
    "* View the schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f97b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  language|\n",
      "+----------+\n",
      "|    Python|\n",
      "|      Java|\n",
      "|       SQL|\n",
      "|         R|\n",
      "|      Ruby|\n",
      "|PowerShell|\n",
      "|   PySpark|\n",
      "|JavaScript|\n",
      "|       C++|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af6b2d",
   "metadata": {},
   "source": [
    "* Output the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684a704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56014b1d",
   "metadata": {},
   "source": [
    "* Show the first five records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03e4fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  Python|\n",
      "|    Java|\n",
      "|     SQL|\n",
      "|       R|\n",
      "|    Ruby|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89054e4f",
   "metadata": {},
   "source": [
    "2) Load the `mpg` dataset as a spark dataframe.\n",
    "\n",
    "a. Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "`The 1999 audi a4 has a 4 cylinder engine.`\n",
    "\n",
    "For each vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58c41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af0e2843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3997ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, min, max, sum, count, mean, avg, concat, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8ed3446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|message                                     |\n",
      "+--------------------------------------------+\n",
      "|This 1999 audi has a 4 cylinder engine.     |\n",
      "|This 1999 audi has a 4 cylinder engine.     |\n",
      "|This 2008 audi has a 4 cylinder engine.     |\n",
      "|This 2008 audi has a 4 cylinder engine.     |\n",
      "|This 1999 audi has a 6 cylinder engine.     |\n",
      "|This 1999 audi has a 6 cylinder engine.     |\n",
      "|This 2008 audi has a 6 cylinder engine.     |\n",
      "|This 1999 audi has a 4 cylinder engine.     |\n",
      "|This 1999 audi has a 4 cylinder engine.     |\n",
      "|This 2008 audi has a 4 cylinder engine.     |\n",
      "|This 2008 audi has a 4 cylinder engine.     |\n",
      "|This 1999 audi has a 6 cylinder engine.     |\n",
      "|This 1999 audi has a 6 cylinder engine.     |\n",
      "|This 2008 audi has a 6 cylinder engine.     |\n",
      "|This 2008 audi has a 6 cylinder engine.     |\n",
      "|This 1999 audi has a 6 cylinder engine.     |\n",
      "|This 2008 audi has a 6 cylinder engine.     |\n",
      "|This 2008 audi has a 8 cylinder engine.     |\n",
      "|This 2008 chevrolet has a 8 cylinder engine.|\n",
      "|This 2008 chevrolet has a 8 cylinder engine.|\n",
      "+--------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    concat(lit(\"This \"), \n",
    "           mpg.year, \n",
    "           lit(\" \"), \n",
    "           mpg.manufacturer, \n",
    "           lit(\" has a \"), \n",
    "           mpg.cyl, \n",
    "           lit(\" cylinder engine.\")).alias('message')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f292d2",
   "metadata": {},
   "source": [
    "b. Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6bf814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9def37cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|     trans|transmission|\n",
      "+----------+------------+\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(av)|        auto|\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|  auto(av)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(s6)|        auto|\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|  auto(s6)|        auto|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(l5)|        auto|\n",
      "|  auto(s6)|        auto|\n",
      "|  auto(s6)|        auto|\n",
      "|  auto(l4)|        auto|\n",
      "|  auto(l4)|        auto|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.trans,\n",
    "          regexp_extract('trans', r'^(.*)\\(', 1).alias('transmission')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead5ff3",
   "metadata": {},
   "source": [
    "3) Load the `tips` dataset as a spark dataframe.\n",
    "\n",
    "a. What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d7e607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = spark.createDataFrame(data('tips'))\n",
    "\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a79f9d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(tips.filter(tips.smoker == 'Yes').count()/tips.count()*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf0bd7c",
   "metadata": {},
   "source": [
    "b. Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1846f633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    tip_percentage|\n",
      "+------------------+\n",
      "|5.9446733372572105|\n",
      "|16.054158607350097|\n",
      "|16.658733936220845|\n",
      "| 13.97804054054054|\n",
      "|14.680764538430255|\n",
      "| 18.62396204033215|\n",
      "| 22.80501710376283|\n",
      "|11.607142857142858|\n",
      "|13.031914893617023|\n",
      "|21.853856562922868|\n",
      "| 16.65043816942551|\n",
      "|14.180374361883155|\n",
      "|10.181582360570687|\n",
      "|16.277807921866522|\n",
      "|20.364126770060686|\n",
      "|18.164967562557923|\n",
      "| 16.16650532429816|\n",
      "|22.774708410067525|\n",
      "|20.624631703005306|\n",
      "|16.222760290556902|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.select((tips.tip/tips.total_bill*100).alias(\"tip_percentage\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d23f8b",
   "metadata": {},
   "source": [
    "c. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d40cdbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----------------+\n",
      "|   sex|smoker|         avg(tip)|\n",
      "+------+------+-----------------+\n",
      "|  Male|    No| 3.11340206185567|\n",
      "|Female|    No|2.773518518518518|\n",
      "|  Male|   Yes|3.051166666666667|\n",
      "|Female|   Yes|2.931515151515151|\n",
      "+------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy('sex', 'smoker').mean('tip').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f69a9",
   "metadata": {},
   "source": [
    "4) Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "* Convert the temperatures to fahrenheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4710ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1e7c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = spark.createDataFrame(data.seattle_weather())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "915f9016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbd231f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------------+\n",
      "|((temp_max * 1.8) + 32)|((temp_min * 1.8) + 32)|\n",
      "+-----------------------+-----------------------+\n",
      "|     55.040000000000006|                   41.0|\n",
      "|                  51.08|                  37.04|\n",
      "|                  53.06|                  44.96|\n",
      "|                  53.96|                  42.08|\n",
      "|     48.019999999999996|                  37.04|\n",
      "|                  39.92|                  35.96|\n",
      "|                  44.96|                  37.04|\n",
      "|                   50.0|                  37.04|\n",
      "|                  48.92|                   41.0|\n",
      "|     42.980000000000004|                  33.08|\n",
      "|     42.980000000000004|                  30.02|\n",
      "|     42.980000000000004|                  28.94|\n",
      "|                   41.0|                  26.96|\n",
      "|                  39.92|                  33.08|\n",
      "|                  33.98|     26.060000000000002|\n",
      "|                  35.06|                  26.96|\n",
      "|                  37.94|                   32.0|\n",
      "|                   32.0|                  26.96|\n",
      "|                  30.02|                  26.96|\n",
      "|                  44.96|                  30.02|\n",
      "+-----------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select(\n",
    "    ((weather.temp_max * (9/5)) + 32),\n",
    "    ((weather.temp_min * (9/5)) + 32)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7939a7ae",
   "metadata": {},
   "source": [
    "* Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1339d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               date|\n",
      "+-------------------+\n",
      "|2012-01-01 00:00:00|\n",
      "|2012-01-02 00:00:00|\n",
      "|2012-01-03 00:00:00|\n",
      "|2012-01-04 00:00:00|\n",
      "|2012-01-05 00:00:00|\n",
      "|2012-01-06 00:00:00|\n",
      "|2012-01-07 00:00:00|\n",
      "|2012-01-08 00:00:00|\n",
      "|2012-01-09 00:00:00|\n",
      "|2012-01-10 00:00:00|\n",
      "|2012-01-11 00:00:00|\n",
      "|2012-01-12 00:00:00|\n",
      "|2012-01-13 00:00:00|\n",
      "|2012-01-14 00:00:00|\n",
      "|2012-01-15 00:00:00|\n",
      "|2012-01-16 00:00:00|\n",
      "|2012-01-17 00:00:00|\n",
      "|2012-01-18 00:00:00|\n",
      "|2012-01-19 00:00:00|\n",
      "|2012-01-20 00:00:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select(weather.date).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15429258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month, year, quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3096fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|month|       average_rain|\n",
      "+-----+-------------------+\n",
      "|   11|  5.354166666666667|\n",
      "|   12|  5.021774193548389|\n",
      "|    3|  4.888709677419355|\n",
      "|   10|  4.059677419354839|\n",
      "|    1| 3.7580645161290316|\n",
      "|    2|  3.734513274336283|\n",
      "|    4|  3.128333333333333|\n",
      "|    9| 1.9624999999999997|\n",
      "|    5| 1.6733870967741935|\n",
      "|    8| 1.3201612903225806|\n",
      "|    6| 1.1075000000000002|\n",
      "|    7|0.38870967741935486|\n",
      "+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn(\"month\", month('date'))\\\n",
    ".groupBy('month')\\\n",
    ".agg(mean('precipitation').alias('average_rain'))\\ #aliasing can only be done with aggregate function when done this way\n",
    ".sort('average_rain', ascending=False)\\ #could also do sort(col('average_rain').desc())\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4350df72",
   "metadata": {},
   "source": [
    "* Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd4d009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|         sum(wind)|\n",
      "+----+------------------+\n",
      "|2012|            1244.7|\n",
      "|2014|1236.5000000000007|\n",
      "|2015|1153.3000000000002|\n",
      "|2013|1100.8000000000006|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn(\"year\", year('date'))\\\n",
    ".groupBy('year')\\\n",
    ".sum('wind')\\\n",
    ".sort(sum('wind').desc())\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f4acb6",
   "metadata": {},
   "source": [
    "* What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8be77f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|drizzle|   10|\n",
      "|   snow|    8|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.filter(month(weather.date) == 1)\\\n",
    ".groupBy(weather.weather).count().sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8ba63",
   "metadata": {},
   "source": [
    "* What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62739415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+\n",
      "|weather|avg(temp_max)|     avg(temp_min)|\n",
      "+-------+-------------+------------------+\n",
      "|    sun|       28.884|15.867999999999995|\n",
      "+-------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.filter((month(weather.date) == 7) & (year(weather.date) == (2013 | 2014)) & (weather.weather == 'sun'))\\\n",
    ".groupBy(weather.weather).mean('temp_max', 'temp_min').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f9adc",
   "metadata": {},
   "source": [
    "* What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e73f1842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1739130434782608"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.filter((quarter('date') == 3) & (year('date') == 2015) & (weather.weather == ('rain' or 'drizzle')))\\\n",
    ".count()/weather.filter((quarter('date') == 3) & (year('date') == 2015)).count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65294c85",
   "metadata": {},
   "source": [
    "* For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77bedd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|year(date)|count|\n",
      "+----------+-----+\n",
      "|      2012|  177|\n",
      "|      2013|  152|\n",
      "|      2014|  150|\n",
      "|      2015|  144|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.filter(weather.precipitation > 0).groupBy(year('date')).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "44302fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|year(date)|count|\n",
      "+----------+-----+\n",
      "|      2012|  366|\n",
      "|      2013|  365|\n",
      "|      2014|  365|\n",
      "|      2015|  365|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.groupBy(year('date')).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1f3bbaf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'DataFrame' and 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0j/dh4q6gzs5xq4fv119n901xmw0000gn/T/ipykernel_45773/998145099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecipitation\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'DataFrame' and 'DataFrame'"
     ]
    }
   ],
   "source": [
    "(weather.filter(weather.precipitation > 0).groupBy(year('date')).count()) / (weather.groupBy(year('date')).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentage of days were rainy in Q3 of 2015?\n",
    "total_days_q3_2015 = weather.filter((year(\"date\") == 2015) & (month(\"date\").between(7, 9))).count()\n",
    "rainy_days_q3_2015 = weather.filter((year(\"date\") == 2015) & (month(\"date\").between(7, 9)) & (weather.precipitation > 0)).count()\n",
    "rainy_percentage_q3_2015 = (rainy_days_q3_2015 / total_days_q3_2015) * 100\n",
    "print(\"Percentage of rainy days in Q3 of 2015:\", rainy_percentage_q3_2015)\n",
    "# For each year, find the percentage of days it rained (had non-zero precipitation)\n",
    "rainy_days_percentage_by_year = weather.groupBy(year(\"date\").alias(\"year\")).agg((sum(when(weather.precipitation > 0, 1)) / count(\"*\") * 100).alias(\"rainy_percentage\"))\n",
    "rainy_days_percentage_by_year.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
